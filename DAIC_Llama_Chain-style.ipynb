{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fb1919b-200c-4c6b-8ec2-a9b0fc1890e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64f500f8-91d5-46fc-badd-79e20196c9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "toks = [2000, 100, 200]\n",
    "\n",
    "its = [\"Transcript:['Ellie: \", \"Synopsis:['The Participant\", \"Sentiment:['The Participant\"]\n",
    "items = ['transcript', 'synopsis', 'sentiment']\n",
    "forms = [\"Transcript:['Ellie: how is life Participant: I dont know ok Ellie: i see, anything else ']\",\n",
    "         \"Synopsis:['Synthetic synopsis here']\",\n",
    "         \"Sentiment:['Detailed sentiment analysis here']\"]\n",
    "\n",
    "rules = [\"\"\"Transcript: The synthetic transcript should follow the adjusted depression score of {PHQ8_Score} where Participant now has {dep}.\n",
    "       Given the input information, focus on making a proactive conversation between Ellie and Participant with coherent responses and a consistent storyline in the same style of the transcript.\n",
    "       The conversation must have a good balance between Ellie's and Participant's dialogue.\"\"\",\n",
    "        \"Synopsis: The synthetic synopsis should succinctly capture the key concerns and topics discussed in the input transcript, providing insightful and reflective observations.\",\n",
    "        \"Sentiment: Provide a detailed sentiment analysis of the synthetic synopsis, identifying and elaborating on the specific emotions expressed.\"\n",
    "        ]\n",
    "depression = [\n",
    "    \"good mental health and no or minimal depression\",\n",
    "    \"mild but bearable depression\",\n",
    "    \"moderate depression, anxiety, or slight stress\",\n",
    "    \"moderately severe depression, anxiety, stress and concerning negative thoughts\",\n",
    "    \"severe depression, anxiety, stress and alarming negative thoughts\"\n",
    "    ]\n",
    "adds = [\"with a different story, background, and location from Participant's life events\",\n",
    "       \"from the synthetic input transcript\",\n",
    "       \"from the synthetic input transcript\"]\n",
    "\n",
    "og_prompt = \"\"\">\n",
    "    <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "    \n",
    "    You are an intelligent data generation assistant tasked with creating a synthetic {item}.\n",
    "\n",
    "    Instructions:\n",
    "    1. Use the input transcript above only as a reference, but create a new {item} in fluent English {add} that matches a depression/PHQ8 score of {PHQ8_Score}.\n",
    "    2. Follow this rule for the generated data:\n",
    "       {rule} \n",
    "       Do not repeat any previous text. Do not cut to other prompts.\n",
    "    \n",
    "    Output the synthetic row in a compact JSON format on a single line without any whitespace, separators, special tokens, or special symbols. For example:\n",
    "    {form}\n",
    "    \n",
    "    Don't copy the example or repeat yourself. Avoid any white space, line breaks, or incomprehensible text.<|eot_id|>\n",
    "    \n",
    "    <|start_header_id|>user<|end_header_id|>\n",
    "    \n",
    "    PHQ8 Score: {PHQ8_Score}\n",
    "    Depression level: Participant has {dep}.\n",
    "    Input Transcript: ['{Transcript}']\n",
    "    <|eot_id|>\n",
    "    \n",
    "    <|start_header_id|>assistant<|end_header_id|>\n",
    "    Output {start}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60441162-9c12-43a4-a1b7-fde1996eeee8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extra_outdir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, d \u001b[38;5;129;01min\u001b[39;00m train\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Clean CSV\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     pid, s \u001b[38;5;241m=\u001b[39m d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubject_id\u001b[39m\u001b[38;5;124m\"\u001b[39m], d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPHQ8_Score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(extra_outdir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/train.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f: js \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      9\u001b[0m     transcript \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([mess[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m mess \u001b[38;5;129;01min\u001b[39;00m js[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n\u001b[1;32m     10\u001b[0m     sgroup \u001b[38;5;241m=\u001b[39m s \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m5\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'extra_outdir' is not defined"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "train = pd.read_csv(\"/data/DAIC_cleaned/train.csv\")\n",
    "sims = 3\n",
    "pref = \"\\'PHQ8_Score\\'\"\n",
    "for i, d in train.iterrows():\n",
    "    # Clean CSV\n",
    "    pid, s = d[\"subject_id\"], d[\"PHQ8_Score\"]\n",
    "    with open(\"train.json\", \"r\") as f: js = json.load(f)\n",
    "    transcript = ' '.join([mess[\"content\"] for mess in js[\"messages\"][1:]])\n",
    "    sgroup = s // 5\n",
    "    scores = random.sample(list(set(range(24)) - set(range(sgroup * 5, (sgroup+1) * 5))), sims)\n",
    "    for score in scores:\n",
    "        error = False\n",
    "        row, q = [pid, score], \"\"\n",
    "        syntrans = \"\"\n",
    "        dep = depression[score//5]\n",
    "        print(row)\n",
    "        for it in range(len(its)):\n",
    "            curtrans = transcript if syntrans == \"\" else syntrans\n",
    "            tok = toks[it]\n",
    "            item, rule, form = items[it], rules[it], forms[it]\n",
    "            if it == 0: rule = rule.format(PHQ8_Score=score,dep=dep)\n",
    "            start = its[it]\n",
    "            pro = og_prompt.format(Transcript=curtrans,PHQ8_Score=score,add=adds[it],\n",
    "                                   item=item,rule=rule,form=form,start=start,dep=dep)\n",
    "            output = \"\"\n",
    "            outtxt = \"./DAIC_style_output/output.txt\"\n",
    "            !tune run generate --config daic_eval_chain_finetune.yml prompt=\"{pro}\" \\\n",
    "                max_new_tokens=\"{tok}\" > {outtxt} 2>&1\n",
    "            try:\n",
    "                with open(outtxt, 'r') as f: output = f.read().rstrip().split(start)\n",
    "                if len(output) == 1: raise ValueError(\"Error in generating output!\")\n",
    "                output = output[-1].replace('\"', \"'\").replace('`', \"'\")\n",
    "                for sy in [\"<|e\", \">\", \"]\", \"}\"]: output = output.split(sy)[0]\n",
    "                if ''.join(re.split(r'Ellie:|Participant:',output)[-4:]).strip() == \"\":\n",
    "                    raise ValueError(\"Output drew a blank!\")\n",
    "                output = output.split(\"\\n\")[0]\n",
    "                if output[-1] != \"'\": output += \"'\"\n",
    "                fout = start.split(\"[\")[-1] + output\n",
    "                row.append(fout)\n",
    "                if it == 0: syntrans = fout\n",
    "            except:\n",
    "                error = True\n",
    "                break\n",
    "        if not error:\n",
    "            print(i, row)\n",
    "            data.append(row)\n",
    "        else: print(\"Error occurred! Starting next one...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0849c3fc-1d79-47ba-bbbe-5a5965b46742",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=[\"Participant_ID\", \"PHQ8_Score\", \"Transcript\", \"Synopsis\", \"Sentiment\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4a2eac-9749-46b7-b852-09db814f7bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = \"DAIC_transcripts\"\n",
    "os.makedirs(dst, exist_ok=True)\n",
    "df.to_csv(dst + \"/DAIC_transcript_style.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9579a48d-cf9f-42b3-8d59-52e1abad5450",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
